{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN_ref.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1GwiDMOyzj-bQg4JjpfC09tVPbjd9VRt6",
      "authorship_tag": "ABX9TyPuwKZN/UAS+Eh+Mfb1YmIU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XenoicZ/EPE/blob/main/GNN_ref.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/atlas-calo-ml/gn4pions_eastbay.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJp9eS9-0mtb",
        "outputId": "0df8a1ed-e0d8-4653-e8e6-cb0d8c0b2c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gn4pions_eastbay'...\n",
            "remote: Enumerating objects: 1068, done.\u001b[K\n",
            "remote: Counting objects: 100% (285/285), done.\u001b[K\n",
            "remote: Compressing objects: 100% (189/189), done.\u001b[K\n",
            "remote: Total 1068 (delta 163), reused 198 (delta 95), pack-reused 783\u001b[K\n",
            "Receiving objects: 100% (1068/1068), 195.30 MiB | 41.70 MiB/s, done.\n",
            "Resolving deltas: 100% (615/615), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!cd gn4pions_eastbay\n",
        "!pip install uproot\n",
        "!pip install graph_nets\n",
        "!pip install sonnet>=2.0.0\n",
        "#!pip install dm-sonnet\n",
        "#!pip install graph_nets \"tensorflow_gpu>=1.15,<2\" \"dm-sonnet<2\" \"tensorflow_probability<0.9\"\n",
        "!pip install graphs\n",
        "!pip install compress_pickle\n",
        "!pip install PyYAML==5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGtVgdFrhHwa",
        "outputId": "8ba692ad-6ce6-41f8-ead0-3af91c836bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: uproot in /usr/local/lib/python3.7/dist-packages (4.2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from uproot) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from uproot) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: graph_nets in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from graph_nets) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from graph_nets) (1.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from graph_nets) (1.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from graph_nets) (57.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from graph_nets) (0.1.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from graph_nets) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from graph_nets) (1.21.6)\n",
            "Requirement already satisfied: dm-sonnet in /usr/local/lib/python3.7/dist-packages (from graph_nets) (2.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->graph_nets) (1.14.1)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->graph_nets) (0.8.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: graphs in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from graphs) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from graphs) (1.4.1)\n",
            "Requirement already satisfied: Cython>=0.21 in /usr/local/lib/python3.7/dist-packages (from graphs) (0.29.30)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.7/dist-packages (from graphs) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from graphs) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->graphs) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->graphs) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->graphs) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->graphs) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->graphs) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.3.1->graphs) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.15->graphs) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.15->graphs) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: compress_pickle in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gn4pions_eastbay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsdtTU0QtzXf",
        "outputId": "6afeea70-ddf4-4d9f-b532-1e25a216780e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gn4pions_eastbay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import uproot as ur\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "#from graph_nets.graphs import GraphsTuple\n",
        "#sys.path.insert(1, '/content/drive/MyDrive/ml4pion')\n",
        "#utils_np = importlib.import_module(\"/content/drive/MyDrive/ml4pion/graph_nets/utils_np.py\")\n",
        "#utils_tf = importlib.import_module(\"/content/drive/MyDrive/ml4pion/graph_nets/utils_tf.py\")\n",
        "#GraphsTuple = importlib.import_module(\"/content/drive/MyDrive/ml4pion/graph_nets/graphs.py\")\n",
        "\n",
        "import sonnet as snt\n",
        "import argparse\n",
        "#!pip install --ignore-installed PyYAML\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "\n",
        "from gn4pions.modules.data import GraphDataGenerator\n",
        "from gn4pions.modules.models import MultiOutWeightedRegressModel\n",
        "from gn4pions.modules.utils import convert_to_tuple\n",
        "\n",
        "sns.set_context('poster')\n",
        "\n",
        "import graph_nets\n",
        "from graph_nets import utils_np\n",
        "from graph_nets import utils_tf\n",
        "import yaml"
      ],
      "metadata": {
        "id": "xJ9cWRBTg4EH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2dedc463-ae05-4b0f-dc0d-4601b148314c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-4-3d97a0f34d0d>\", line 19, in <module>\n",
            "    import sonnet as snt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sonnet/__init__.py\", line 21, in <module>\n",
            "    from sonnet import distribute\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sonnet/distribute.py\", line 21, in <module>\n",
            "    from sonnet.src.distribute.batch_norm import CrossReplicaBatchNorm\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sonnet/src/distribute/batch_norm.py\", line 22, in <module>\n",
            "    from sonnet.src import batch_norm\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sonnet/src/batch_norm.py\", line 34, in <module>\n",
            "    class BaseBatchNorm(base.Module):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sonnet/src/batch_norm.py\", line 137, in BaseBatchNorm\n",
            "    offset: Optional[tf.Tensor] = None):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sonnet/src/utils.py\", line 180, in smart_autograph\n",
            "    f_autograph = tf.autograph.to_graph(f)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/api.py\", line 690, in to_graph_v1\n",
            "    experimental_optional_features=experimental_optional_features)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/api.py\", line 614, in to_graph\n",
            "    return conversion.convert(entity, program_ctx)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/conversion.py\", line 322, in convert\n",
            "    free_nonglobal_var_names)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/conversion.py\", line 240, in _convert_with_cache\n",
            "    entity, program_ctx)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/conversion.py\", line 469, in convert_entity_to_ast\n",
            "    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/conversion.py\", line 630, in convert_func_to_ast\n",
            "    node, source = parser.parse_entity(f, future_features=future_features)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/pyct/parser.py\", line 53, in parse_entity\n",
            "    original_source = inspect_utils.getimmediatesource(entity)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/pyct/inspect_utils.py\", line 126, in getimmediatesource\n",
            "    _fix_linecache_record(obj)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/pyct/inspect_utils.py\", line 118, in _fix_linecache_record\n",
            "    if hasattr(m, '__file__') and m.__file__ == obj_file:\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/__init__.py\", line 39, in <module>\n",
            "    from tensorflow.contrib import compiler\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/compiler/__init__.py\", line 21, in <module>\n",
            "    from tensorflow.contrib.compiler import jit\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/compiler/__init__.py\", line 22, in <module>\n",
            "    from tensorflow.contrib.compiler import xla\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/compiler/xla.py\", line 22, in <module>\n",
            "    from tensorflow.python.estimator import model_fn as model_fn_lib\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/estimator/model_fn.py\", line 26, in <module>\n",
            "    from tensorflow_estimator.python.estimator import model_fn\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/__init__.py\", line 8, in <module>\n",
            "    from tensorflow_estimator._api.v1 import estimator\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\", line 8, in <module>\n",
            "    from tensorflow_estimator._api.v1.estimator import experimental\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py\", line 8, in <module>\n",
            "    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 27, in <module>\n",
            "    from tensorflow_estimator.python.estimator import estimator\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 36, in <module>\n",
            "    from tensorflow.python.profiler import trace\n",
            "ImportError: cannot import name 'trace' from 'tensorflow.python.profiler' (/tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
            "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model config\n",
        "config_file = '/content/gn4pions_eastbay/gn4pions/configs/weightedRegress.yaml'\n",
        "config = yaml.load(open(config_file), Loader=yaml.FullLoader)\n",
        "\n",
        "\n",
        "# Data config\n",
        "data_config = config['data']\n",
        "\n",
        "data_dir = data_config['data_dir']\n",
        "num_train_files = data_config['num_train_files']\n",
        "num_val_files = data_config['num_val_files']\n",
        "batch_size = data_config['batch_size']\n",
        "shuffle = data_config['shuffle']\n",
        "num_procs = data_config['num_procs']\n",
        "preprocess = data_config['preprocess']\n",
        "output_dir = '/content/drive/MyDrive/ml4pion/model'\n",
        "already_preprocessed = data_config['already_preprocessed']  # Set to false when running training for first time\n",
        "\n",
        "\n",
        "# Model Config\n",
        "model_config = config['model']\n",
        "\n",
        "concat_input = model_config['concat_input']\n",
        "\n",
        "\n",
        "# Traning Config\n",
        "train_config = config['training']\n",
        "\n",
        "epochs = train_config['epochs']\n",
        "learning_rate = train_config['learning_rate']\n",
        "alpha = train_config['alpha']\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = str(train_config['gpu'])\n",
        "log_freq = train_config['log_freq']\n",
        "save_dir = train_config['save_dir'] + config_file.replace('.yaml','').split('/')[-1] + '_' + time.strftime(\"%Y%m%d\")\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "yaml.dump(config, open(save_dir + '/config.yaml', 'w'))"
      ],
      "metadata": {
        "id": "u73Ivc5pvETm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_dir = '/content/drive/MyDrive/ml4pion/ML4Pion/PFNet/v01-45/pipm'\n",
        "#files_names = np.zeros(100)\n",
        "#for i in range(100):\n",
        "#  files_names[i] = \n",
        "#files_names = data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b5YYzV5sAmVv",
        "outputId": "7cbbc448-4482-4bdc-c127-ce8bb70f20ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/workspace/hip/ML4Jets/regression_images/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data and create data generators\n",
        "data_dir_0 = '/content/drive/MyDrive/ml4pion/data/pion_files/pi0_files/'\n",
        "data_dir_pm = '/content/drive/MyDrive/ml4pion/data/pion_files/pion_files/'\n",
        "pi0_files = np.array(0)\n",
        "pion_files = np.array(0)\n",
        "for i in range(1,11):\n",
        "  pi0_files = np.append(pi0_files, data_dir_0 + '0' + str(i+10) + '.npy')\n",
        "  pion_files = np.append(pion_files, data_dir_pm + '0' + str(i) + '.npy' )\n",
        "\n",
        "#pi0_files = np.sort(glob.glob(data_dir+'*graphs.v01*/*pi0*/*root'))\n",
        "#pion_files = np.sort(glob.glob(data_dir+'*graphs.v01*/*pion*/*root'))\n",
        "\n",
        "\n",
        "num_train_files = 10\n",
        "num_val_files = 10\n",
        "train_start = 10\n",
        "train_end = train_start + num_train_files\n",
        "val_end = train_end + num_val_files\n",
        "\n",
        "pi0_train_files = pi0_files[train_start:train_end]\n",
        "pi0_val_files = pi0_files[train_end:val_end]\n",
        "pion_train_files = pion_files[train_start:train_end]\n",
        "pion_val_files = pion_files[train_end:val_end]\n",
        "\n",
        "train_output_dir = None\n",
        "val_output_dir = None\n",
        "\n",
        "\n",
        "already_preprocessed = False\n",
        "\n",
        "# Get Data\n",
        "if preprocess:\n",
        "    train_output_dir = output_dir + '/train/'\n",
        "    val_output_dir = output_dir + '/val/'\n",
        "\n",
        "    if already_preprocessed:\n",
        "        train_files = np.sort(glob.glob(train_output_dir+'*.p'))[:num_train_files]\n",
        "        val_files = np.sort(glob.glob(val_output_dir+'*.p'))[:num_val_files]\n",
        "\n",
        "        pi0_train_files = train_files\n",
        "        pi0_val_files = val_files\n",
        "        pion_train_files = None\n",
        "        pion_val_files = None\n",
        "\n",
        "        train_output_dir = None\n",
        "        val_output_dir = None\n",
        "\n",
        "# Traning Data Generator\n",
        "# Will preprocess data if it doesnt find pickled files\n",
        "data_gen_train = GraphDataGenerator(pi0_file_list=pi0_train_files,\n",
        "                                    pion_file_list=pion_train_files,\n",
        "                                    cellGeo_file='/content/drive/MyDrive/ml4pion/data/pion_files/cell_geo.root',\n",
        "                                    batch_size=batch_size,\n",
        "                                    shuffle=shuffle,\n",
        "                                    num_procs=num_procs,\n",
        "                                    preprocess=preprocess,\n",
        "                                    output_dir=train_output_dir)\n",
        "\n",
        "# Validation Data generator\n",
        "# Will preprocess data if it doesnt find pickled files\n",
        "data_gen_val = GraphDataGenerator(pi0_file_list=pi0_val_files,\n",
        "                                  pion_file_list=pion_val_files,\n",
        "                                  cellGeo_file='/content/drive/MyDrive/ml4pion/data/pion_files/cell_geo.root',\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_procs=num_procs,\n",
        "                                  preprocess=preprocess,\n",
        "                                  output_dir=val_output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kto17gjA0F4t",
        "outputId": "00c3d1bb-30fd-4a9a-8ca2-a506c991d190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessing and saving data to /content/drive/MyDrive/ml4pion/model/train/\n",
            "Processing file number 0\n",
            "Finished processing 0 files\n",
            "\n",
            "Preprocessing and saving data to /content/drive/MyDrive/ml4pion/model/val/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get batch of data\n",
        "def get_batch(data_iter):\n",
        "    for graphs, targets in data_iter:\n",
        "        graphs = convert_to_tuple(graphs)\n",
        "        targets = tf.convert_to_tensor(targets)\n",
        "        yield graphs, targets\n",
        "        \n",
        "# Define loss function        \n",
        "mae_loss = tf.keras.losses.MeanAbsoluteError()\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def loss_fn(targets, regress_preds, class_preds):\n",
        "    regress_loss = mae_loss(targets[:,:1], regress_preds)\n",
        "    class_loss = bce_loss(targets[:,1:], class_preds)\n",
        "    combined_loss = alpha*regress_loss + (1 - alpha)*class_loss \n",
        "    return regress_loss, class_loss, combined_loss"
      ],
      "metadata": {
        "id": "TL_uiK5nEGcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xTV5TlwpGhM",
        "outputId": "563b0343-096e-4a0e-d708-6a987a8a3a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gn4pions.modules.data.GraphDataGenerator at 0x7f01dce59f90>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getattr(samp_graph, 'n_edge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "4y1JkV75n-cC",
        "outputId": "f4b20c3e-333b-434c-ff35-e732871b6774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-5de086931489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamp_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_edge'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'n_edge'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graph_nets import graphs\n",
        "graphs.ALL_FIELDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQs2vtD0Qd8m",
        "outputId": "dd48bebe-840b-4f30-bf7a-2c721cc06916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('nodes', 'edges', 'receivers', 'senders', 'globals', 'n_node', 'n_edge')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample graph for tf.function decorator\n",
        "#samp_graph, samp_target = next(get_batch(data_gen_train.generator()))\n",
        "#data_gen_train.kill_procs()\n",
        "#graph_spec = utils_tf.specs_from_graphs_tuple(samp_graph, True, True, True)\n",
        "\n",
        "\n",
        "# Traning set\n",
        "#@tf.function(input_signature=[graph_spec, tf.TensorSpec(shape=[None,2], dtype=tf.float32)])\n",
        "def train_step(graphs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        regress_output, class_output = model(graphs)\n",
        "        regress_preds = regress_output.globals\n",
        "        class_preds = class_output.globals\n",
        "        regress_loss, class_loss, loss = loss_fn(targets, regress_preds, class_preds)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return regress_loss, class_loss, loss\n",
        "\n",
        "\n",
        "# Validation Step\n",
        "#@tf.function(input_signature=[graph_spec, tf.TensorSpec(shape=[None,2], dtype=tf.float32)])\n",
        "def val_step(graphs, targets):\n",
        "    regress_output, class_output = model(graphs)\n",
        "    regress_preds = regress_output.globals\n",
        "    class_preds = class_output.globals\n",
        "    regress_loss, class_loss, loss = loss_fn(targets, regress_preds, class_preds)\n",
        "    return regress_loss, class_loss, loss, regress_preds, class_preds"
      ],
      "metadata": {
        "id": "eSLrdUGIHzvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model \n",
        "model = MultiOutWeightedRegressModel(global_output_size=1, num_outputs=2, model_config=model_config)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Average epoch losses\n",
        "training_loss_epoch = []\n",
        "training_loss_regress_epoch = []\n",
        "training_loss_class_epoch = []\n",
        "val_loss_epoch = []\n",
        "val_loss_regress_epoch = []\n",
        "val_loss_class_epoch = []\n",
        "\n",
        "# Model checkpointing, load latest model if available\n",
        "checkpoint = tf.train.Checkpoint(module=model)\n",
        "checkpoint_prefix = os.path.join(save_dir, 'latest_model')\n",
        "latest = tf.train.latest_checkpoint(save_dir)\n",
        "if latest is not None:\n",
        "    checkpoint.restore(latest)\n",
        "else:\n",
        "    checkpoint.save(checkpoint_prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "rzRL98XarQaH",
        "outputId": "90665980-6bf2-4aa1-c2c7-0c2d153e8553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3cd7c933afe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiOutWeightedRegressModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_output_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gn4pions_eastbay/gn4pions/modules/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, global_output_size, num_outputs, model_config, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m                \u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                name=\"MultiOutWeightedRegressModel\"):\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiOutWeightedRegressModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_blocks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'build'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMLP(snt.Module):\n",
        "   def __init__(self, name=None):\n",
        "     super(MyMLP, self).__init__(name=name)\n",
        "     self.hidden1 = snt.Linear(1024, name=\"hidden1\")\n",
        "     self.output = snt.Linear(10, name=\"output\")\n",
        "\n",
        "   def __call__(self, x):\n",
        "     x = self.hidden1(x)\n",
        "     x = tf.nn.relu(x)\n",
        "     x = self.output(x)\n",
        "     return x"
      ],
      "metadata": {
        "id": "JRup0ltBrWLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "lines = inspect.getsource(sonnet.Module)\n",
        "print(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "5r9ygWruw-pL",
        "outputId": "f176f0b9-de1f-4909-d9a6-d7fe324d133a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-97727cb79f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msonnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'sonnet' has no attribute 'Module'"
          ]
        }
      ]
    }
  ]
}